{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division # backward compatibility for python2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.special\n",
    "import operator\n",
    "import random\n",
    "#library for plotting arrays\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# A particularly interesting backend, provided by IPython, is the inline backend. \n",
    "# This is available only for the Jupyter Notebook and the Jupyter QtConsole. \n",
    "# It can be invoked as follows: %matplotlib inline\n",
    "# With this backend, the output of plotting commands is displayed inline \n",
    "# within frontends like the Jupyter notebook, directly below the code cell that produced it. \n",
    "# The resulting plots are inside this notebook, not an external window.\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creating minidatsets for kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "972\n"
     ]
    }
   ],
   "source": [
    "#splitting the dataset into trainning=80% and test=20%\n",
    "df = pd.read_csv(\"mnist.csv\")\n",
    "mn = np.random.rand(len(df)) < 0.2\n",
    "df_mini_mnist = df[mn]\n",
    "\n",
    "\n",
    "print(len(df_mini_mnist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use index=false so pandas dont create a extra index column\n",
    "df_mini_mnist.to_csv('mini_mnist.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# set global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets to read\n",
    "# you can change these when trying out other datasets\n",
    "data_file = \"mini_mnist.csv\"\n",
    "\n",
    "class_index = 0 # on inspection of the csv file we see that the class appears in 0th position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read and split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(filename, class_idx=class_index, split=0.8):\n",
    "    dataframe = pd.read_csv(filename)\n",
    "    #dataframe = dataframe.sample(len(dataframe))\n",
    "    instances = dataframe.values\n",
    "    \n",
    "\n",
    "    print (\"Class Index: \"+str(class_idx))\n",
    "    # divide data into label and feature sets.\n",
    "    X = instances[:,0:784] # you may need to change these depending on which dataset you are use\n",
    "    Y = instances[:,class_idx] \n",
    "    \n",
    "   \n",
    "    X_train = [] # features for the train set\n",
    "    Y_train = [] # class labels for the train set\n",
    "    X_test = [] # features for the test set\n",
    "    Y_test = [] # class labels for the test set\n",
    "    \n",
    "    # the zip iterator is a neat construct in Python\n",
    "    # it lets you iterate over 2 arrays / lists structures \n",
    "    # importantly it iterates upto the length of the smallest structure of the two \n",
    "    # in our case X and Y will be of same length\n",
    "    for  x, y in zip(X, Y): \n",
    "        if random.random() < split: # Return the next random floating point number in the range [0.0, 1.0) and compare\n",
    "            X_train.append(x)\n",
    "            Y_train.append(y)\n",
    "        else:\n",
    "            X_test.append(x)\n",
    "            Y_test.append(y)       \n",
    "    print(\"train set size: \", len(X_train))       \n",
    "    print(\"test set size: \", len(X_test))\n",
    "    \n",
    "    return X_train, Y_train, X_test, Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define similarity matrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Within our class we now need code for each of the components of k-NN.\n",
    "#First, lets create a method that will measure the distance between two vectors.\n",
    "def euclidean(instance1, instance2):\n",
    "        '''\n",
    "        Calculates euclidean distance between two instances of data\n",
    "        instance1 will be a List of Float values\n",
    "        instance2 will be a List of Float values\n",
    "        length will be an Integer denoting the length of the Lists\n",
    "        '''\n",
    "        distance = 0\n",
    "        for val1, val2 in zip(instance1, instance2):            \n",
    "            distance += pow((val1 - val2), 2)\n",
    "        \n",
    "        distance = pow(distance, 1/2)\n",
    "             \n",
    "              \n",
    "        return 1 / (1+ distance)\n",
    "    \n",
    "\n",
    "def manhattan(instance1, instance2):\n",
    "        '''\n",
    "        Calculates manhattan distance between two instances of data\n",
    "        instance1 will be a List of Float values\n",
    "        instance2 will be a List of Float values\n",
    "        length will be an Integer denoting the length of the Lists\n",
    "        '''\n",
    "        distance = 0\n",
    "        for val1, val2 in zip(instance1, instance2):\n",
    "            distance += abs(val1 - val2)      \n",
    "              \n",
    "        return 1 / (1+ distance)\n",
    "    \n",
    "def dot_product(instance1, instance2):\n",
    "        '''\n",
    "        Calculates dot product between two instances \n",
    "        instance1 will be a List of Float values\n",
    "        instance2 will be a List of Float values\n",
    "        length will be an Integer denoting the length of the Lists\n",
    "        '''\n",
    "        return np.dot(instance1, instance2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define evaulation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #Finally, we can test to see how many of the test instances we got correct\n",
    "    def accuracy(results):\n",
    "        correct = 0\n",
    "        for predict, target in results:\n",
    "            \n",
    "            if predict == target:\n",
    "                correct += 1\n",
    "        return (correct/float(len(results))) * 100.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bulid the KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class kNN:\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    X_train, Y_train : list\n",
    "    these consists of the training set feature values and associated class labels\n",
    "    k : int\n",
    "    specify the number of neighbours\n",
    "    sim : literal\n",
    "    specify the name of the similarity metric (e.g. manhattan, eucliedean)\n",
    "    weighted : Boolean\n",
    "    specify the voting strategy as weighted or not weighted by similarity values\n",
    "  \n",
    "    Attributes\n",
    "    -----------  \n",
    "    Results : list\n",
    "      Target and predicted class labels for the test data.    \n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    def __init__(self, X_train, Y_train, k=3, sim=manhattan, weighted=False):\n",
    "        self.X_train = X_train\n",
    "        self.Y_train = Y_train\n",
    "        \n",
    "        if k <= len(self.X_train):\n",
    "            self.k = k # set the k value for neighbourhood size\n",
    "        else:\n",
    "            self.k = len(self.X_train) # to ensure the get_neighbours dont crash\n",
    "    \n",
    "        self.similarity = sim # specify a sim metric that has been pre-defined e.g. manhattan or euclidean\n",
    "        \n",
    "        self.weighted = weighted # boolean to choose between weighted / unweighted majority voting\n",
    "        \n",
    "        #store results from testing \n",
    "        self.results= []\n",
    "        \n",
    "    #With k-NN, we are interested in finding the k number of points with the greatest similarity \n",
    "    # to the the query or test instance.\n",
    "    def get_neighbours(self, test_instance):\n",
    "        '''\n",
    "        Locate most similar neighbours \n",
    "        X_train will be a containing features (Float) values (i.e. your training data)\n",
    "        Y_train will be the corresponding class labels for each instance in X_train\n",
    "        test_instance will be a List of Float values (i.e. a query instance)\n",
    "        '''\n",
    "        similarities = [] # collection to store the similarities to be computed\n",
    "\n",
    "        for train_instance, y in zip(self.X_train, self.Y_train): #for each member of the training set\n",
    "            sim = self.similarity(test_instance, train_instance) #calculate the similarity to the test instance\n",
    "            \n",
    "            similarities.append((y, sim)) #add the actual label of the example and the computed similarity to a collection \n",
    "        #print(distances)\n",
    "        similarities.sort(key = operator.itemgetter(1), reverse = True) #sort the collection by decreasing similarity\n",
    "        neighbours = [] # holds the k most similar neighbours\n",
    "        for x in range(self.k): #extract the k top indices of the collection for return\n",
    "            neighbours.append(similarities[x])\n",
    "\n",
    "        return neighbours\n",
    "\n",
    "    # given the neighbours make a prediction\n",
    "    # the boolean parameter when set to False will use unweighted majority voting; otherwise weighted majority voting\n",
    "    # weighting can be helpful to break any ties in voting\n",
    "    def predict(self, neighbours):\n",
    "        '''\n",
    "        Summarise a prediction based upon weighted neighbours calculation\n",
    "        '''\n",
    "        class_votes = {}\n",
    "        for x in range(len(neighbours)):\n",
    "            response = neighbours[x][0]\n",
    "            if response in class_votes:\n",
    "                class_votes[response] += (1-self.weighted) + (self.weighted * neighbours[x][1]) #if not weighted simply add 1\n",
    "                #class_votes[response] += [1, neighbours[x][1]][weighted == True] \n",
    "              \n",
    "            else:\n",
    "                class_votes[response] = (1-self.weighted) + (self.weighted * neighbours[x][1])\n",
    "                #class_votes[response] = [1, neighbours[x][1]][weighted == True] \n",
    "                \n",
    "        #print(class_votes)\n",
    "        sorted_votes = sorted(class_votes, key = lambda k: (class_votes[k], k), reverse = True)\n",
    "        #print(sorted_votes)\n",
    "        return sorted_votes[0]\n",
    "    \n",
    "    #iterate through all the test data to calculate accuracy\n",
    "    def test(self, X_test, Y_test):\n",
    "        self.results = [] # store the predictions returned by kNN\n",
    "\n",
    "        for test_instance, target_label in zip(X_test, Y_test):\n",
    "            neighbours = self.get_neighbours(test_instance)\n",
    "            predict_label = self.predict(neighbours)\n",
    "            self.results.append([predict_label, target_label])\n",
    "            #print('> predicted = ', result,', actual = ', test_label)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Index: 0\n",
      "train set size:  780\n",
      "test set size:  192\n"
     ]
    }
   ],
   "source": [
    "#Load the dataset and maintain the features (X) and class labels (Y) separately  \n",
    "# make sure you understand what the 4 and 0.8 default values are in the call\n",
    "# you may have to modify these depending on the dataset you work with.\n",
    "X_train, Y_train, X_test, Y_test = load_dataset(data_file, 0, 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply kNN to test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN Accuracy on test set is:  83.85416666666666\n"
     ]
    }
   ],
   "source": [
    "#create an instance of kNN \n",
    "# pass the training instances with their class labels (i.e. X_train and Y_train)\n",
    "# we will use the default kNN class settings for parameters i.e. k=3, sim=manhattan, weighted=False\n",
    "\n",
    "knn = kNN(X_train, Y_train)\n",
    "knn.test(X_test, Y_test) # now get the predictions on the test set\n",
    "\n",
    "print(\"kNN Accuracy on test set is: \", accuracy(knn.results))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN with multiple values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Index: 0\n",
      "train set size:  762\n",
      "test set size:  210\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train, X_test, Y_test = load_dataset(data_file, 0, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup the kNN instances ...\n",
      "Results from trials... [[91.42857142857143, 87.61904761904762, 84.28571428571429, 82.85714285714286, 82.85714285714286], [91.42857142857143, 89.52380952380953, 84.28571428571429, 83.33333333333334, 84.28571428571429]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Setup the kNN instances ...\")\n",
    "knn_list = []\n",
    "ks = [1, 10, 20, 30 ,40] # try a few different values for k\n",
    "is_weighted = [False, True] # try two different forms of voting\n",
    "\n",
    "# iterate over different voting strategies\n",
    "for weighted in is_weighted:\n",
    "    knn_list_element = [] # first set of knns with a specified voting scheme\n",
    "    #iterate over different k values\n",
    "    for k in ks:\n",
    "        #create the different instances of the kNN class\n",
    "        knn = kNN(X_train, Y_train, k, euclidean, weighted)\n",
    "        \n",
    "        knn_list_element.append(knn)\n",
    "        pass\n",
    "    \n",
    "    knn_list.append(knn_list_element)# now append the set of models \n",
    "    pass\n",
    "\n",
    "\n",
    "#lets test the kNNs \n",
    "#iterate through each model and accumilate number of correct predictions\n",
    "knn_results = []\n",
    "knn_result_element = []\n",
    "\n",
    "for knn1 in knn_list:\n",
    "    knn_result_element = []\n",
    "\n",
    "    for knn2 in knn1:\n",
    "        knn2.test(X_test, Y_test)\n",
    "             \n",
    "        knn_result_element.append(accuracy(knn2.results))\n",
    "        \n",
    "        pass\n",
    "    pass\n",
    "    knn_results.append(knn_result_element)\n",
    "    pass\n",
    "print(\"Results from trials...\", knn_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "N = len(ks) # this is the number of results we want to plot pn the x-axis\n",
    "ind = np.arange(N) \n",
    "\n",
    "performance1 = knn_results[0]\n",
    "performance2 = knn_results[1]\n",
    "\n",
    "width = 0.35 # width of the bar      \n",
    "plt.bar(ind, performance1, width, label='Unweighted')\n",
    "plt.bar(ind + width, performance2, width, label='Weighted')\n",
    "\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('k value')\n",
    "plt.title('kNN performance(Mnist Dataset)')\n",
    "\n",
    "plt.xticks(ind + width / 2, ks)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
